{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cwbNIEZnXPLd"},"outputs":[],"source":["# Importing dependencies\n","import numpy as np\n","import torch\n","import tensorflow as tf\n","import json\n","import time\n","import random\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import adam\n","from torch.optim import sgd\n","from google.colab import drive\n","import requests\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"53yqnua4BDK0"},"source":["Data getting part"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16963,"status":"ok","timestamp":1709745468497,"user":{"displayName":"Mariano Santos","userId":"18234865401952934666"},"user_tz":0},"id":"Q93zZWB7ogrt","outputId":"d3eae089-d6fe-46dd-cbec-582d6cd4dd54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Mounting drive\n","drive.mount(\"/content/drive\")\n","#What crypto?\n","crypto = \"XRP\""]},{"cell_type":"markdown","metadata":{"id":"rJkCUaDoivj7"},"source":["Algumas funções e classes para a rede neuronal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vc01tQq2i3IT"},"outputs":[],"source":["#Creating Class with pytorch\n","\n","class Model(nn.Module):\n","  #Input Layer (=length of inputs) --> Hidden Layer (x5) --> Output layer(Buy or sell)\n","  def __init__(self, in_features=207,h1=140, h2=100, h3=80, h4=50, h5=30, h6=16, h7=5, ol=2):\n","    super().__init__()\n","    self.fc1 = nn.Linear(in_features, h1)\n","    self.fc2 = nn.Linear(h1, h2)\n","    self.fc3 = nn.Linear(h2, h3)\n","    self.fc4 = nn.Linear(h3, h4)\n","    self.fc5 = nn.Linear(h4, h5)\n","    self.fc6 = nn.Linear(h5, h6)\n","    self.fc7 = nn.Linear(h6, h7)\n","    self.out = nn.Linear(h7, ol)\n","\n","  def forward(self, X):\n","    X = F.relu(self.fc1(X))\n","    X = F.relu(self.fc2(X))\n","    X = F.relu(self.fc3(X))\n","    X = F.relu(self.fc4(X))\n","    X = F.relu(self.fc5(X))\n","    X = F.relu(self.fc6(X))\n","    X = F.relu(self.fc7(X))\n","    X = self.out(X)\n","    #X = F.softmax(self.out(X))\n","\n","    return X\n","\n","torch.manual_seed(0.01)\n","model = Model()\n","model.load_state_dict(torch.load(\"/content/drive/MyDrive/Databases/Databases Weights And Biases/\"+crypto+\"_crypto_predict_AI.pt\"))\n","\n","#Accuracy Function\n","def accuracy(y_true, y_pred):\n","  sum = 0\n","  for i, j in zip(y_true, y_pred):\n","    if np.argmax(i) == np.argmax(j):\n","      sum += 1\n","  return (sum / len(y_true))\n"]},{"cell_type":"markdown","metadata":{"id":"B38kXVcABOZL"},"source":["Training and testing split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1aEkgmPOytTl"},"outputs":[],"source":["with open(\"/content/drive/MyDrive/Databases/Databases Weights And Biases/Training_Continuom/continuom_inputs_\"+crypto, \"r\") as file:\n","  data = json.load(file)\n","X_train = torch.Tensor(data[\"X_TR\"])\n","X_test = torch.Tensor(data[\"X_TT\"])\n","y_train = torch.Tensor(data[\"Y_TR\"])\n","y_test = torch.Tensor(data[\"Y_TT\"])"]},{"cell_type":"markdown","metadata":{"id":"OB2QotqsFUGJ"},"source":["Putting some relevant variables in"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YovI-fpPFOhS"},"outputs":[],"source":["learning_rate = 5e-4\n","iterations = 1000000"]},{"cell_type":"markdown","metadata":{"id":"re9f5bOLBzIr"},"source":["Loss Function and Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkasRAH3B3tj"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"gGq-5lSOF6Bq"},"source":["Starting to train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-J6ytvHF8gR"},"outputs":[],"source":["loss_opt = []\n","using = 1\n","for i in range(iterations):\n","  y_pred = model.forward(X_train)\n","\n","  loss = criterion(y_pred, y_train)\n","  #accuracy_m = accuracy(y_true, y_pred)\n","\n","  loss_opt.append(loss.detach().numpy())\n","\n","  if i % 10 == 0:\n","    print(\"Epoch:\", i, \"Loss:\", loss) #\"Accuracy:\", accuracy_m)\n","\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","  if i % 2500 == 0:\n","    torch.save(model.state_dict(), \"/content/drive/MyDrive/Databases/Databases Weights And Biases/\"+crypto+\"_crypto_predict_AI.pt\")\n","    print(\"Saved\")\n","\n","  using += 1\n"]},{"cell_type":"markdown","metadata":{"id":"vfOhr4yKI42n"},"source":["Watching it grow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeUpymAvI3XX"},"outputs":[],"source":["if using == len(loss_opt)-1:\n","  using += 1\n","if using == len(loss_opt)+1:\n","  using -= 1\n","plt.plot(range(using), loss_opt)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ERH7IbKUKq2H"},"source":["Evaluate Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwKk8oF0KqZg"},"outputs":[],"source":["criterion1 = nn.CrossEntropyLoss()\n","correct = 0\n","with torch.no_grad():\n","  y_val = model.forward(X_test)\n","  loss = criterion1(y_val, y_test)\n","\n","loss\n","\n","#Accuracy\n","with torch.no_grad():\n","  for i, data in enumerate(X_test):\n","    y_eval = model.forward(data)\n","    if y_eval.argmax().item() == y_test[i].argmax():\n","      correct += 1\n","\n","    #print(i, str(y_val.argmax()))\n","for i, j in zip(y_val, y_test):\n","  print(\"Prediction:\", i.argmax())\n","  print(\"Real:\", j.argmax())\n","\n","\n","\n","print(correct)\n","print(len(y_test))\n","\n","print(correct / len(y_test))\n"]},{"cell_type":"markdown","metadata":{"id":"AokXmR3kQ5Xe"},"source":["Inserting information"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6uY6w7C5Q78g"},"outputs":[],"source":["new_data = torch.tensor()\n","prediction = (model.forward(new_data)).argmax()\n","if prediction == 0:\n","  print(\"Buy\")\n","if prediction == 1:\n","  print(\"Sell\")\n","print(prediction)"]},{"cell_type":"markdown","metadata":{"id":"-gTKT94pTtia"},"source":["Saving model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyMk9ssSTx24"},"outputs":[],"source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/Databases/Databases Weights And Biases/\"+crypto+\"_crypto_predict_AI.pt\")"]},{"cell_type":"markdown","metadata":{"id":"3JKrugdcI0-Z"},"source":["Creating new model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRsvddxOIyjZ"},"outputs":[],"source":["new_model = Model()\n","new_model.load_state_dict(torch.load(\"/content/drive/MyDrive/Databases/Databases Weights And Biases/\"+crypto+\"_crypto_predict_AI.pt\"))\n","\n","#Checking if deployed correctly\n","new_model.eval()"]},{"cell_type":"code","source":["try:\n","    with open(\"/content/drive/MyDrive/Databases/database_\"+crypto+\"_T.json\", \"r\") as file:\n","        jr = json.load(file)\n","except Exception as e:\n","    print(\"An error occured:\", e)\n","\n","def get_last_it(json_file):\n","    iter = 0\n","    for i in json_file:\n","        if int(i) > iter:\n","            iter = int(i)\n","    return iter+1\n","\n","last_it = get_last_it(jr)\n","\n","# Initializing some variables\n","X = []\n","y_true = []\n","\n","\n","# Getting the data organized\n","for i in range(1, last_it, 1):\n","  i = str(i)\n","  try:\n","    prices = jr[i][\"Prices\"]\n","    volume = jr[i][\"Volume\"]\n","    Google_Trends_Data = jr[i][\"Google Trends\"]\n","    RSI = jr[i][\"RSI\"]\n","    Market_cap = jr[i][\"Market_cap\"]\n","    market_cap_TVL = jr[i][\"MC/TVL\"]\n","    outputs = jr[i][\"Price_12_hours\"]\n","    inputs_a = prices + volume + RSI + Google_Trends_Data + Market_cap + market_cap_TVL\n","  except Exception as e:\n","    inputs_a = jr[i][\"Data\"]\n","  if len(inputs_a) == 207:\n","    X.append(inputs_a)\n","    if outputs > 0.0: #mudar dependendo da crypto\n","        y_true.append([1, 0])\n","    else:\n","        y_true.append([0, 1])\n","\n","def Baralha_Listas(lista1, lista2, maximo_len=None):\n","    indexes = []\n","    for a, i in enumerate(lista1):\n","        indexes.append(a)\n","    if maximo_len is None:\n","        maximo_len = min(len(lista1), len(lista2))\n","    else:\n","        maximo_len = min(maximo_len, min(len(lista1), len(lista2)))\n","    lista1_baralhada = []\n","    lista2_baralhada = []\n","    lista_indexes = set()\n","    while len(lista1_baralhada) < maximo_len and len(lista2_baralhada) < maximo_len:\n","        random_index2 = random.randint(0, len(indexes)-1)\n","        random_index = indexes[random_index2]\n","        if random_index not in lista_indexes:  # Verificar se o índice já foi utilizado\n","            lista_indexes.add(random_index)\n","            lista1_baralhada.append(lista1[random_index])\n","            lista2_baralhada.append(lista2[random_index])\n","        del indexes[random_index2]\n","    return lista1_baralhada, lista2_baralhada\n","def test_train(X, y, test_size=0.2):\n","    X2_train = []\n","    y2_train = []\n","    X2_test = []\n","    y2_test = []\n","    le = len(X)\n","    len_per_train = round((1-test_size)*le)\n","    len_per_test = int(le - len_per_train)\n","    X_bar, Y_bar = Baralha_Listas(X, y)\n","    for i in range(len_per_train):\n","        y2_train.append(Y_bar[i])\n","        X2_train.append(X_bar[i])\n","    for j in range(len_per_test):\n","        X2_test.append(X_bar[j+len_per_train])\n","        y2_test.append(Y_bar[j+len_per_train])\n","    return X2_train, X2_test, y2_train, y2_test\n","\n","X_train2, X_test2, y_train2, y_test2 = test_train(X, y_true, test_size = 0.1)\n","X_train = torch.FloatTensor(X_train2)\n","X_test = torch.FloatTensor(X_test2)\n","y_train = torch.FloatTensor(y_train2)\n","y_test = torch.FloatTensor(y_test2)"],"metadata":{"id":"A_mJj1r49RcY"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1b7hLeK9NvjtfW_JdZjAQ7sMMxgYtfERm","authorship_tag":"ABX9TyPzPdPPbRX2ubD9pP5lwE9U"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}